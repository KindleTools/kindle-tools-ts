# Architecture

Technical overview of kindle-tools-ts for contributors and developers who want to understand or extend the codebase.

## Project Structure

```
kindle-tools-ts/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/               # Orchestration & System-wide logic
â”‚   â”‚   â”œâ”€â”€ constants.ts    # System constants
â”‚   â”‚   â””â”€â”€ processor.ts    # Dedup, merge, link notes (The "Processor")
â”‚   â”‚
â”‚   â”œâ”€â”€ domain/             # Pure Business Logic (Entities & Rules)
â”‚   â”‚   â”œâ”€â”€ stats.ts        # Statistics logic
â”‚   â”‚   â”œâ”€â”€ geo-location.ts # Coordinates & Distance
â”‚   â”‚   â”œâ”€â”€ tag-extractor.ts # Business rules for cleaning tags
â”‚   â”‚   â”œâ”€â”€ page-utils.ts   # Page estimation heuristics
â”‚   â”‚   â””â”€â”€ sanitizers.ts   # Title/Author cleaning rules
â”‚   â”‚
â”‚   â”œâ”€â”€ importers/          # Data Ingestion
â”‚   â”‚   â”œâ”€â”€ txt/            # Kindle TXT parser details
â”‚   â”‚   â”‚   â”œâ”€â”€ core/       # Tokenizer, Parser, Language Detector
â”‚   â”‚   â”‚   â””â”€â”€ utils/      # Parser-specific utils (e.g. date-parser)
â”‚   â”‚   â”œâ”€â”€ json/           # JSON Importer
â”‚   â”‚   â””â”€â”€ csv/            # CSV Importer
â”‚   â”‚
â”‚   â”œâ”€â”€ exporters/          # Export Adapters
â”‚   â”‚   â”œâ”€â”€ json.exporter.ts
â”‚   â”‚   â”œâ”€â”€ csv.exporter.ts
â”‚   â”‚   â”œâ”€â”€ markdown.exporter.ts
â”‚   â”‚   â”œâ”€â”€ obsidian.exporter.ts
â”‚   â”‚   â”œâ”€â”€ joplin.exporter.ts
â”‚   â”‚   â””â”€â”€ html.exporter.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/              # Generic, App-Agnostic Utilities
â”‚   â”‚   â”œâ”€â”€ normalizers.ts  # String normalization
â”‚   â”‚   â”œâ”€â”€ dates.ts        # Date formatting
â”‚   â”‚   â”œâ”€â”€ hashing.ts      # SHA-256 generation
â”‚   â”‚   â”œâ”€â”€ similarity.ts   # Math/Algo (Jaccard)
â”‚   â”‚   â”œâ”€â”€ tar.ts          # Archive creation
â”‚   â”‚   â””â”€â”€ zip.ts          # Archive creation
â”‚   â”‚
â”‚   â”œâ”€â”€ types/              # Shared Types
â”‚   â”œâ”€â”€ gui/                # Browser Testing GUI
â”‚   â”œâ”€â”€ templates/          # Handlebars templates
â”‚   â”œâ”€â”€ index.ts            # Public API
â”‚   â””â”€â”€ cli.ts              # Command Line Interface
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/               # Unit tests
â”‚   â”œâ”€â”€ integration/        # Pipeline tests
â”‚   â””â”€â”€ fixtures/           # Test data
â”‚
â””â”€â”€ dist/                   # Build output
```

## Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        My Clippings.txt                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. TOKENIZER                                                        â”‚
â”‚     - Split by "==========" separator                                â”‚
â”‚     - Normalize line endings                                         â”‚
â”‚     - Remove BOM                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. LANGUAGE DETECTOR                                                â”‚
â”‚     - Analyze metadata patterns ("Added on", "AÃ±adido el", etc.)     â”‚
â”‚     - Support: EN, ES, PT, DE, FR, IT, ZH, JA, KO, NL, RU            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PARSER                                                           â”‚
â”‚     - Extract: title, author, type, page, location, date, content    â”‚
â”‚     - Generate deterministic ID (SHA-256 truncated)                  â”‚
â”‚     - Detect DRM limit messages                                      â”‚
â”‚     - Identify sideloaded books (.pdf, .epub)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. PROCESSOR (optional steps)                                       â”‚
â”‚     â”œâ”€ removeDuplicates()     â†’ Exact duplicate removal              â”‚
â”‚     â”œâ”€ smartMergeHighlights() â†’ Merge overlapping selections         â”‚
â”‚     â”œâ”€ linkNotesToHighlights()â†’ Associate notes with highlights      â”‚
â”‚     â”œâ”€ extractTagsFromLinkedNotes() â†’ Parse #tags from notes         â”‚
â”‚     â”œâ”€ flagSuspiciousHighlights()   â†’ Mark accidental/fragments      â”‚
â”‚     â””â”€ flagFuzzyDuplicates()  â†’ Jaccard similarity detection         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. EXPORTER                                                         â”‚
â”‚     - JSON, CSV, Markdown, Obsidian, Joplin JEX, HTML                â”‚
â”‚     - Configurable folder structure and author case                  â”‚
â”‚     - Tag synchronization across formats                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Model

### Clipping

The core data structure representing a single clipping:

```typescript
interface Clipping {
  // Identification
  id: string;                    // Deterministic SHA-256 hash (12 chars)
  blockIndex: number;            // Original position in file

  // Book metadata
  title: string;                 // Clean title
  titleRaw: string;              // Original title (preserved)
  author: string;                // Extracted author
  authorRaw: string;             // Original author (preserved)

  // Content
  content: string;               // Clean content
  contentRaw: string;            // Original content (preserved)
  type: 'highlight' | 'note' | 'bookmark' | 'clip' | 'article';

  // Location
  page: number | null;
  location: {
    raw: string;                 // "100-105"
    start: number;
    end: number | null;
  };

  // Date
  date: Date | null;
  dateRaw: string;               // Original date string

  // Flags
  isLimitReached: boolean;       // DRM limit detected
  isEmpty: boolean;              // No content
  language: SupportedLanguage;
  source: 'kindle' | 'sideload';

  // Stats
  wordCount: number;
  charCount: number;

  // Linking (after processing)
  linkedNoteId?: string;         // ID of linked note
  linkedHighlightId?: string;    // ID of linked highlight
  note?: string;                 // Merged note content
  tags?: string[];               // Extracted tags
}
```

## Key Algorithms

### Deterministic ID Generation

IDs are generated using SHA-256 hash of normalized content, ensuring:
- Same clipping always gets same ID
- Idempotent imports (no duplicates on re-import)
- Collision-resistant (12-char hex prefix)

```typescript
const id = sha256(`${title}|${author}|${type}|${location.raw}|${contentPrefix}`).slice(0, 12);
```

### Smart Merge (Overlapping Highlights)

When you extend a highlight in Kindle, it creates a new entry. Smart merge detects these overlaps:

```
Original:  "The quick brown"
Extended:  "The quick brown fox jumps"
Result:    Keep the longer version, merge tags
```

Detection criteria:
- Same title
- Overlapping location ranges
- One content is subset of the other (or high Jaccard similarity)

### Note-to-Highlight Linking

Notes in Kindle are stored separately. Linking associates them:

1. **Range Coverage** (preferred): Note location within highlight's location range
   ```
   Highlight: locations 100-150
   Note: location 120 â†’ LINKED
   ```

2. **Proximity Fallback**: Distance â‰¤ 10 locations
   ```
   Highlight: location 100
   Note: location 105 â†’ LINKED (within 10)
   ```

### Tag Extraction

Tags are extracted from note content:
- Hashtag format: `#important #review`
- Comma/semicolon separated: `important, review`
- Newline separated

After extraction:
- Tags are added to the linked highlight's `tags` array
- Original note content is preserved in `note` field

## Joplin JEX Format

The JEX format is a TAR archive containing:

```
clippings.jex/
â”œâ”€â”€ {id}.md              # Root notebook
â”œâ”€â”€ {id}.md              # Author notebook (optional)
â”œâ”€â”€ {id}.md              # Book notebook
â”œâ”€â”€ {id}.md              # Note (clipping)
â”œâ”€â”€ {id}.md              # Tag
â””â”€â”€ {id}.md              # Note-Tag association
```

Each file has YAML-like metadata at the bottom:
```markdown
[0042] ðŸ“– Quote content here...

**Book:** Title
**Author:** Author Name

---

> The actual highlight text

id: {32-char-deterministic-id}
parent_id: {notebook-id}
created_time: 2024-01-01T00:00:00.000Z
type_: 1  # 1=note, 2=folder, 5=tag, 6=note_tag
```

Deterministic IDs ensure:
- Re-importing updates existing notes instead of creating duplicates
- Consistent hierarchy across imports

## Design Decisions

### Why SHA-256 for IDs?

- **Deterministic**: Same input always produces same output
- **Collision-resistant**: 12 hex chars = 48 bits = very low collision probability
- **Cross-platform**: Works identically in Node.js and browser

### Why Preserve Raw Fields?

The `titleRaw`, `authorRaw`, `contentRaw` fields preserve original data because:
- User can verify cleaning/normalization was correct
- Debugging parsing issues
- Potential future re-processing with different options

### Why Tags in Frontmatter (Obsidian)?

Following Obsidian best practices:
- Tags in YAML frontmatter are indexed by Obsidian
- No hashtags in YAML (they make tags invalid)
- Merged with default tags (`kindle`, `highlights`)

### Why 3-Level Hierarchy for Joplin?

`Root > Author > Book > Notes` mirrors typical library organization:
- Users with many books can navigate by author first
- Configurable: can disable author level for flat structure

## Testing Strategy

```
tests/
â”œâ”€â”€ unit/                    # Isolated function tests
â”‚   â”œâ”€â”€ tokenizer.test.ts    # Block splitting
â”‚   â”œâ”€â”€ parser.test.ts       # Metadata extraction
â”‚   â”œâ”€â”€ processor.test.ts    # Dedup, merge, link
â”‚   â”œâ”€â”€ exporters.test.ts    # All export formats
â”‚   â”œâ”€â”€ normalizers.test.ts  # Unicode, BOM
â”‚   â”œâ”€â”€ sanitizers.test.ts   # Title/author cleaning
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ integration/             # Full pipeline tests
â”‚   â””â”€â”€ pipeline.test.ts     # Parse â†’ Process â†’ Export
â”‚
â””â”€â”€ fixtures/
    â””â”€â”€ sample-clippings.ts  # Test data
```

**Coverage targets**: 80% for lines, functions, branches, statements

## Browser Compatibility

The library is isomorphic (works in Node.js and browser):

- **Node.js**: File system access for `parseFile()`
- **Browser**: String parsing only via `parseString()`

The GUI (`src/gui/`) uses Vite for development and demonstrates browser usage.

## Dependencies

**Runtime**:
- `date-fns`: Multi-locale date parsing
- `handlebars`: Template engine for exports
- `jszip`: Archive creation (Joplin JEX, etc.)
- `zod`: Schema validation

**Development**:
- `tsup`: Build (ESM + CJS + DTS)
- `vitest`: Testing
- `biome`: Linting/formatting
- `husky`: Git hooks
- `changesets`: Versioning

### Architecture Principles (Refactor 2026)

This project strictly adheres to Clean Architecture principles to ensure scalability and maintainability.

#### 1. Factory Pattern & Dependency Injection
We use **Factory Method** patterns to instantiate Importers and Exporters. This decouples the CLI/Consumer from concrete implementations.

- **ImporterFactory:** Dynamically selects the correct parser based on file signature/extension.
- **ExporterFactory:** Provides the requested `Exporter` implementation based on the format string.

#### 2. Domain-Driven Design & Clean Architecture
The project is structured to separate "Business Rules" from "Infrastructure" and "Orchestration".

- **`@domain/*` (The "What"):** Contains pure business logic and rules (e.g., *How do we calculate reading stats?*, *What defines a valid tag?*). These modules are completely independent of the rest of the system.
- **`@core/*` (The "How"):** The application layer that orchestrates the data flow. It uses the Domain to process data but doesn't define the rules itself.
- **`@utils/*` (The "Tools"):** Generic, app-agnostic utilities (e.g., *How to zip a file?*, *How to hash a string?*).

#### 3. Strict Layer Boundaries (Path Aliases)
We enforce structure via TypeScript path aliases:

- `#domain/*`: **Pure Business Logic**. No dependencies on Core or Importers.
- `#core/*`: **Orchestration Logic**. Connects Domain, Importers, and Exporters.
- `#importers/*`: **Adapters** for external data formats.
- `#exporters/*`: **Adapters** for output formats.
- `#utils/*`: **Generic Tools**. Zero dependencies on app logic.
- `#app-types/*`: **Shared Domain Types**.

#### 4. Unified Processing Pipeline
Regardless of the input source (Raw Text, JSON backup, CSV), all data flows through the same **Pipeline**:
1. **Import** (Normalize into `Clipping[]`)
2. **Process** (Deduplicate, Merge, Link Notes) -> *Centralized in `@core/processor`*
3. **Export** (Transform into target format)

This ensures that a JSON backup, when re-imported, undergoes the same rigorous cleanup and deduplication as a raw Kindle file.

### Toolchain & DevOps Strategy (2026 Standards)

The project leverages a "Bleeding Edge, Yet Stable" stack to maximize developer velocity and correctness.

#### 1. High-Performance Tooling
We prioritize tools written in Rust/Go for sub-second feedback loops:
- **Biome:** Replaces ESLint + Prettier. 20x faster, zero-config, handles formatting and linting in one pass.
- **Tsup (esbuild):** Instant builds for the library. Zero config required for ESM/CJS interop.
- **Vitest:** Instant test suite execution with Vite integration (replacing Jest).
- **Turborepo:** Intelligent remote caching. If you only touch the GUI, the Library tests won't re-run in CI.

#### 2. Strict Type Safety
- **Strict Mode:** Enabled in `tsconfig`.
- **`arethetypeswrong`:** Validates `package.json` exports to prevent "it works on my machine" issues for consumers using different module resolution strategies (NodeNext, Bundler, etc.).

#### 3. Monorepo-Lite Structure
Even though it's a single library, we treat it as a monorepo (Library + GUI + Docs) using **pnpm workspaces** + **Turbo**. This allows us to scale the "ecosystem" (e.g. adding a VSCode extension or a Web App later) without restructuring the repo.

#### 4. Import Strategy: Native Node Subpath Imports
To ensure rock-solid compatibility with modern Node.js ESM standards (`NodeNext`), we strictly avoid fragile `tsconfig` `paths`. Instead, we use **Native Node Subpath Imports** (`#alias` prefix).

- **Mechanism:** Mapped in `package.json` under `"imports"`.
  ```json
  "imports": {
    "#core/*.js": "./src/core/*.ts"
  }
  ```
- **Benefit:** This is supported natively by Node.js, and correctly resolved by TypeScript, Esbuild, and Vite without relying on brittle build-time path transformations. It guarantees that our internal aliases behave identically in dev, test, and production builds.
